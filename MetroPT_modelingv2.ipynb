{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c79fb6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\91770\\anaconda3\\lib\\site-packages (0.12.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602fc65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\91770\\anaconda3\\lib\\site-packages (from optuna) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from optuna) (21.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from optuna) (1.4.22)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91770\\anaconda3\\lib\\site-packages (from optuna) (4.62.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\91770\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\91770\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\91770\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 383.6/383.6 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   --------------------------------------- 233.6/233.6 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, Mako, colorlog, alembic, optuna\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcc40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\91770\\anaconda3\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\91770\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   --------------------------------------- 124.9/124.9 MB 26.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467c172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac7713df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91770\\anaconda3\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91770\\anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py:203: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "# Load Data\n",
    "DATA_PATH = pathlib.Path(\"C:/Ahsan.docx/PROJECT/MetroPT_project/MetroPT/\")\n",
    "df = pd.read_feather(DATA_PATH / \"Classification.feather\")\n",
    "\n",
    "# Prepare Data\n",
    "X = df.drop(columns=[\"timestamp\", \"Target\"])  # Drop timestamp\n",
    "y = df[\"Target\"]\n",
    "\n",
    "nm_undersampler = NearMiss(version=3, n_neighbors_ver3=3, n_jobs=-1) # Warning takes very long to run\n",
    "X, y = nm_undersampler.fit_resample(X, y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42099, stratify=y)\n",
    "\n",
    "# Normalize Data (Important for Logistic Regression & SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3cbe21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function for Logistic Regression\n",
    "def objective_logistic(trial, X_train, X_val, y_train, y_val):\n",
    "    params = {\n",
    "        \"C\": trial.suggest_float(\"C\", 0.0001,1000, log=True),\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"penalty\" : \"l2\",\n",
    "        \"max_iter\": 1000,\n",
    "        \"random_state\": 42099\n",
    "    }\n",
    "\n",
    "    # Create and train the model\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    preds = model.predict_proba(X_val)\n",
    "\n",
    "    logloss_scores = []\n",
    "    logloss_scores.append(log_loss(y_val, preds))\n",
    "\n",
    "    return logloss_scores[-1]  # Return the latest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e42a782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function for Random Forest\n",
    "def objective_rf(trial, X_train, X_val, y_train, y_val):\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"min_samples_split\": trial.suggest_float(\"min_samples_split\",0.001, 0.01, log= True), \n",
    "        \"min_samples_leaf\": trial.suggest_float(\"min_samples_leaf\",0.001, 0.01, log= True), \n",
    "        \"max_features\": \"log2\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 10),\n",
    "        \"random_state\": 42099\n",
    "    }\n",
    "        \n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict_proba(X_val)\n",
    "    \n",
    "    #     logloss_scores = []\n",
    "    #     logloss_scores.append(log_loss(y_val, preds))\n",
    "\n",
    "    return log_loss(y_val, preds)  # Return the latest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "964683f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function for XGBoost\n",
    "def objective_xgb(trial, X_train, X_val, y_train, y_val):\n",
    "    params = {\n",
    "        \"objective\": \"multi:softmax\",  # or \"multi:softprob\"\n",
    "#         \"num_class\": 3,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"n_estimators\": 200,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.001, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 9, 12),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 5, 8),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 0.01, 5.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0, log=True),\n",
    "#         \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 0.01, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 0.01, 10.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "        \"random_state\": 42099,\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_val)\n",
    "#     logloss_scores.append(log_loss(y_val, preds))\n",
    "\n",
    "    return log_loss(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1bbfb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterTuner:\n",
    "    def __init__(self, objective_func, n_trials=50, pruner=None):\n",
    "        self.objective_func = objective_func\n",
    "        self.n_trials = n_trials\n",
    "        self.pruner = pruner if pruner else optuna.pruners.MedianPruner()\n",
    "        self.study = None\n",
    "\n",
    "    def tune(self, X_train, X_val, y_train, y_val):\n",
    "        \"\"\"Runs hyperparameter tuning using Optuna\"\"\"\n",
    "        def objective(trial):\n",
    "            return self.objective_func(trial, X_train, X_val, y_train, y_val)\n",
    "        \n",
    "        self.study = optuna.create_study(direction=\"minimize\", pruner=self.pruner)\n",
    "        self.study.optimize(objective, n_trials=self.n_trials) \n",
    "        \n",
    "        return self.study.best_params, self.study.best_value\n",
    "\n",
    "    def get_best_params(self):\n",
    "        \"\"\"Retrieve best parameters after tuning\"\"\"\n",
    "        return self.study.best_params if self.study else None\n",
    "\n",
    "    def get_best_score(self):\n",
    "        \"\"\"Retrieve best score after tuning\"\"\"\n",
    "        return self.study.best_value if self.study else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d54c7f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 17:00:01,179] A new study created in memory with name: no-name-be91013d-5f09-4728-b271-42c07c7499f0\n",
      "[I 2025-02-21 17:00:01,568] Trial 0 finished with value: 0.9529519843001338 and parameters: {'C': 95.1271683229839}. Best is trial 0 with value: 0.9529519843001338.\n",
      "[I 2025-02-21 17:00:01,931] Trial 1 finished with value: 0.9529085669980438 and parameters: {'C': 0.32151444848143884}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:02,289] Trial 2 finished with value: 0.9529538428580157 and parameters: {'C': 0.2240858130329955}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:02,678] Trial 3 finished with value: 0.9529523965147062 and parameters: {'C': 12.638943983698182}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:02,901] Trial 4 finished with value: 0.9535152778638091 and parameters: {'C': 0.005853452343654696}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:03,285] Trial 5 finished with value: 0.9529520540554304 and parameters: {'C': 44.91804863350325}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:03,384] Trial 6 finished with value: 0.9842745101428025 and parameters: {'C': 0.0001685734830710139}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:03,835] Trial 7 finished with value: 0.9529525821457873 and parameters: {'C': 0.43839922979752133}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:04,118] Trial 8 finished with value: 0.9531438847844644 and parameters: {'C': 0.012361300910569825}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:04,454] Trial 9 finished with value: 0.9529831159977331 and parameters: {'C': 0.04944772943954641}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:04,861] Trial 10 finished with value: 0.952953857105728 and parameters: {'C': 3.254161530036882}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:05,266] Trial 11 finished with value: 0.9529519291477444 and parameters: {'C': 836.8160373036734}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:05,681] Trial 12 finished with value: 0.9529519304964271 and parameters: {'C': 702.6999214185957}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:05,798] Trial 13 finished with value: 0.9711512963858163 and parameters: {'C': 0.0003412338432474328}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:06,220] Trial 14 finished with value: 0.9529519304451012 and parameters: {'C': 707.0110356465086}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:06,615] Trial 15 finished with value: 0.9529703741959392 and parameters: {'C': 1.5345548998490395}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:06,794] Trial 16 finished with value: 0.9579669624157854 and parameters: {'C': 0.0011929648904992144}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:07,257] Trial 17 finished with value: 0.9529519998359279 and parameters: {'C': 76.14497590572554}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:07,590] Trial 18 finished with value: 0.9529958666628017 and parameters: {'C': 0.07503011931335742}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:08,026] Trial 19 finished with value: 0.9529528960246194 and parameters: {'C': 6.304787192428924}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:08,456] Trial 20 finished with value: 0.952952928799135 and parameters: {'C': 0.7435827381040776}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:08,849] Trial 21 finished with value: 0.9529519281651256 and parameters: {'C': 971.9806511686268}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:09,285] Trial 22 finished with value: 0.9529519281005666 and parameters: {'C': 982.4027352253464}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:09,670] Trial 23 finished with value: 0.9529519480791109 and parameters: {'C': 227.5056429328003}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:10,072] Trial 24 finished with value: 0.9529521849582598 and parameters: {'C': 22.634102378122353}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:10,458] Trial 25 finished with value: 0.9529519528751297 and parameters: {'C': 192.0884264411505}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:10,830] Trial 26 finished with value: 0.9529519447385026 and parameters: {'C': 261.03472490717377}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:11,197] Trial 27 finished with value: 0.952952211160755 and parameters: {'C': 20.599997084618604}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:11,400] Trial 28 finished with value: 0.9537204559199667 and parameters: {'C': 0.004731338305105511}. Best is trial 1 with value: 0.9529085669980438.\n",
      "[I 2025-02-21 17:00:11,785] Trial 29 finished with value: 0.9529519756097086 and parameters: {'C': 110.55188100329256}. Best is trial 1 with value: 0.9529085669980438.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: ({'C': 0.32151444848143884}, 0.9529085669980438)\n"
     ]
    }
   ],
   "source": [
    "# Tune Logistic Regression\n",
    "tuner = HyperparameterTuner(objective_func=objective_logistic, n_trials=30)\n",
    "best_params_logistic = tuner.tune(X_train, X_val, y_train, y_val)\n",
    "print(\"Best Logistic Regression Params:\", best_params_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30ddc117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-21 18:38:48,826] A new study created in memory with name: no-name-550b7ca4-d18b-45f6-83f6-475d63f75776\n",
      "[I 2025-02-21 18:38:52,804] Trial 0 finished with value: 0.6674836875328193 and parameters: {'min_samples_split': 0.005649947680359575, 'min_samples_leaf': 0.0011596787527683007, 'max_depth': 8}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:38:56,739] Trial 1 finished with value: 0.6813540161330318 and parameters: {'min_samples_split': 0.00885430001392939, 'min_samples_leaf': 0.003742701665602881, 'max_depth': 9}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:00,037] Trial 2 finished with value: 0.7377429011306188 and parameters: {'min_samples_split': 0.007132384998227272, 'min_samples_leaf': 0.0011641650301377256, 'max_depth': 6}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:03,751] Trial 3 finished with value: 0.6946041019805849 and parameters: {'min_samples_split': 0.0034970366409850804, 'min_samples_leaf': 0.001125183499650979, 'max_depth': 7}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:07,655] Trial 4 finished with value: 0.6827358627997496 and parameters: {'min_samples_split': 0.00974017647702791, 'min_samples_leaf': 0.003562305706050433, 'max_depth': 9}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:10,518] Trial 5 finished with value: 0.7963942892462923 and parameters: {'min_samples_split': 0.0033144764898084844, 'min_samples_leaf': 0.005579190232719991, 'max_depth': 5}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:13,990] Trial 6 finished with value: 0.7446458857255788 and parameters: {'min_samples_split': 0.0010467357150673528, 'min_samples_leaf': 0.008139328234999691, 'max_depth': 8}. Best is trial 0 with value: 0.6674836875328193.\n",
      "[I 2025-02-21 18:39:18,059] Trial 7 finished with value: 0.6583248542727806 and parameters: {'min_samples_split': 0.0019200680202826547, 'min_samples_leaf': 0.002434698064970995, 'max_depth': 9}. Best is trial 7 with value: 0.6583248542727806.\n",
      "[I 2025-02-21 18:39:21,382] Trial 8 finished with value: 0.7359948725783999 and parameters: {'min_samples_split': 0.0056192988768972475, 'min_samples_leaf': 0.0013093310611777573, 'max_depth': 6}. Best is trial 7 with value: 0.6583248542727806.\n",
      "[I 2025-02-21 18:39:25,204] Trial 9 finished with value: 0.6829207860776783 and parameters: {'min_samples_split': 0.0010851190670746653, 'min_samples_leaf': 0.0026293579455310525, 'max_depth': 8}. Best is trial 7 with value: 0.6583248542727806.\n",
      "[I 2025-02-21 18:39:29,558] Trial 10 finished with value: 0.6386673014134268 and parameters: {'min_samples_split': 0.0019216352863094326, 'min_samples_leaf': 0.0021319902745516903, 'max_depth': 10}. Best is trial 10 with value: 0.6386673014134268.\n",
      "[I 2025-02-21 18:39:34,161] Trial 11 finished with value: 0.6354395774441668 and parameters: {'min_samples_split': 0.0018233227079512131, 'min_samples_leaf': 0.002038252574220385, 'max_depth': 10}. Best is trial 11 with value: 0.6354395774441668.\n",
      "[I 2025-02-21 18:39:38,891] Trial 12 finished with value: 0.6316008753077826 and parameters: {'min_samples_split': 0.0019799304741617884, 'min_samples_leaf': 0.0018565430546073469, 'max_depth': 10}. Best is trial 12 with value: 0.6316008753077826.\n",
      "[I 2025-02-21 18:39:43,493] Trial 13 finished with value: 0.6306356908051145 and parameters: {'min_samples_split': 0.0019026235675375812, 'min_samples_leaf': 0.0018039138332663982, 'max_depth': 10}. Best is trial 13 with value: 0.6306356908051145.\n",
      "[I 2025-02-21 18:39:48,046] Trial 14 finished with value: 0.6281930877749322 and parameters: {'min_samples_split': 0.0024473688165058977, 'min_samples_leaf': 0.001701828605765819, 'max_depth': 10}. Best is trial 14 with value: 0.6281930877749322.\n",
      "[I 2025-02-21 18:39:52,564] Trial 15 finished with value: 0.6266239950269881 and parameters: {'min_samples_split': 0.0027514449530154036, 'min_samples_leaf': 0.0016119539549210892, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:39:56,822] Trial 16 finished with value: 0.6417739933717953 and parameters: {'min_samples_split': 0.0026570362725660125, 'min_samples_leaf': 0.0015629388791367125, 'max_depth': 9}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:00,505] Trial 17 finished with value: 0.7104111262989392 and parameters: {'min_samples_split': 0.002766804934976888, 'min_samples_leaf': 0.002985625773360586, 'max_depth': 7}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:04,964] Trial 18 finished with value: 0.6295291859950787 and parameters: {'min_samples_split': 0.004141258592301183, 'min_samples_leaf': 0.001541703366615486, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:08,878] Trial 19 finished with value: 0.6943328050259033 and parameters: {'min_samples_split': 0.0014050898023273883, 'min_samples_leaf': 0.004688111465308639, 'max_depth': 9}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:12,414] Trial 20 finished with value: 0.7523993129947396 and parameters: {'min_samples_split': 0.004275547713742582, 'min_samples_leaf': 0.0098498760877817, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:16,943] Trial 21 finished with value: 0.6280753720429688 and parameters: {'min_samples_split': 0.004281008309664224, 'min_samples_leaf': 0.0015146933245071361, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:21,268] Trial 22 finished with value: 0.6356830435854245 and parameters: {'min_samples_split': 0.0025113410277481456, 'min_samples_leaf': 0.001431161107559118, 'max_depth': 9}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:25,774] Trial 23 finished with value: 0.6311945614903844 and parameters: {'min_samples_split': 0.004641105164420651, 'min_samples_leaf': 0.0016675443657906454, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:30,194] Trial 24 finished with value: 0.649134981234316 and parameters: {'min_samples_split': 0.0024607805484636136, 'min_samples_leaf': 0.002418353711374397, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:34,464] Trial 25 finished with value: 0.6338556471643313 and parameters: {'min_samples_split': 0.003636708010346668, 'min_samples_leaf': 0.0010324745789652328, 'max_depth': 9}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:38,429] Trial 26 finished with value: 0.6600747077651616 and parameters: {'min_samples_split': 0.002912367990454708, 'min_samples_leaf': 0.0013509088731906815, 'max_depth': 8}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:42,815] Trial 27 finished with value: 0.6386673014134268 and parameters: {'min_samples_split': 0.0014431875912813415, 'min_samples_leaf': 0.0021255792644791476, 'max_depth': 10}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:47,097] Trial 28 finished with value: 0.6684621214534248 and parameters: {'min_samples_split': 0.005589889797740011, 'min_samples_leaf': 0.0029327291956184652, 'max_depth': 9}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:51,134] Trial 29 finished with value: 0.6580206195975887 and parameters: {'min_samples_split': 0.0022043497022239907, 'min_samples_leaf': 0.0012686892811559632, 'max_depth': 8}. Best is trial 15 with value: 0.6266239950269881.\n",
      "[I 2025-02-21 18:40:55,664] Trial 30 finished with value: 0.6183332599524719 and parameters: {'min_samples_split': 0.004866214852634862, 'min_samples_leaf': 0.0010026935975640887, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:00,180] Trial 31 finished with value: 0.6224593532074669 and parameters: {'min_samples_split': 0.0051374742893694324, 'min_samples_leaf': 0.0010015933264776176, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:04,652] Trial 32 finished with value: 0.6362233876776088 and parameters: {'min_samples_split': 0.007115832119597349, 'min_samples_leaf': 0.0010312496461615031, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:08,834] Trial 33 finished with value: 0.6513599105934047 and parameters: {'min_samples_split': 0.006833206711532116, 'min_samples_leaf': 0.0011712567609997767, 'max_depth': 9}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:13,206] Trial 34 finished with value: 0.6239006408568492 and parameters: {'min_samples_split': 0.004999738685973977, 'min_samples_leaf': 0.0011560656687351425, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:17,425] Trial 35 finished with value: 0.6497570717346904 and parameters: {'min_samples_split': 0.006315301332589704, 'min_samples_leaf': 0.0011679799067525313, 'max_depth': 9}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:20,478] Trial 36 finished with value: 0.791137701460253 and parameters: {'min_samples_split': 0.008447170674829545, 'min_samples_leaf': 0.0010380548907133887, 'max_depth': 5}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:24,214] Trial 37 finished with value: 0.6951054362242388 and parameters: {'min_samples_split': 0.005011091925565346, 'min_samples_leaf': 0.0012270607499222314, 'max_depth': 7}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:27,708] Trial 38 finished with value: 0.737394142133919 and parameters: {'min_samples_split': 0.003721943411866646, 'min_samples_leaf': 0.0010203463341604312, 'max_depth': 6}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:31,925] Trial 39 finished with value: 0.6491428901394187 and parameters: {'min_samples_split': 0.008445290863509496, 'min_samples_leaf': 0.001375279134413519, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:36,267] Trial 40 finished with value: 0.6444003256565678 and parameters: {'min_samples_split': 0.005340103343848624, 'min_samples_leaf': 0.0011545503372136887, 'max_depth': 9}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:40,752] Trial 41 finished with value: 0.6233413152919282 and parameters: {'min_samples_split': 0.004222566727851612, 'min_samples_leaf': 0.0014338425227827544, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:45,260] Trial 42 finished with value: 0.6332144034262517 and parameters: {'min_samples_split': 0.006058456468016867, 'min_samples_leaf': 0.0013402417306375618, 'max_depth': 10}. Best is trial 30 with value: 0.6183332599524719.\n",
      "[I 2025-02-21 18:41:49,843] Trial 43 finished with value: 0.6146603658272988 and parameters: {'min_samples_split': 0.0030959784653249956, 'min_samples_leaf': 0.0011366757909473594, 'max_depth': 10}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:41:54,214] Trial 44 finished with value: 0.6350570896585238 and parameters: {'min_samples_split': 0.003274489670978211, 'min_samples_leaf': 0.001091622360155974, 'max_depth': 9}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:41:58,741] Trial 45 finished with value: 0.6212167410629025 and parameters: {'min_samples_split': 0.003893562230759816, 'min_samples_leaf': 0.0012305666503569497, 'max_depth': 10}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:42:03,320] Trial 46 finished with value: 0.6203313551966448 and parameters: {'min_samples_split': 0.0039045992235460223, 'min_samples_leaf': 0.001248187038651852, 'max_depth': 10}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:42:07,472] Trial 47 finished with value: 0.6792128196548025 and parameters: {'min_samples_split': 0.003804030595236658, 'min_samples_leaf': 0.003948130758336948, 'max_depth': 10}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:42:11,475] Trial 48 finished with value: 0.6576912120267117 and parameters: {'min_samples_split': 0.003117583461844315, 'min_samples_leaf': 0.0012520642106032868, 'max_depth': 8}. Best is trial 43 with value: 0.6146603658272988.\n",
      "[I 2025-02-21 18:42:15,672] Trial 49 finished with value: 0.6477487904763942 and parameters: {'min_samples_split': 0.00482681157521532, 'min_samples_leaf': 0.0019402529565285518, 'max_depth': 9}. Best is trial 43 with value: 0.6146603658272988.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Params: {'min_samples_split': 0.0030959784653249956, 'min_samples_leaf': 0.0011366757909473594, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Tune Random Forest\n",
    "tuner = HyperparameterTuner(objective_func=objective_rf, n_trials=50)\n",
    "best_params_rf = tuner.tune(X_train, X_val, y_train, y_val)\n",
    "print(\"Best Random Forest Params:\", best_params_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "053c38b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-28 15:48:15,924] A new study created in memory with name: no-name-f72859f5-ded0-4d61-a8d8-ce38681dccf7\n",
      "[I 2025-02-28 15:48:16,868] Trial 0 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:17,781] Trial 1 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:18,633] Trial 2 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:19,867] Trial 3 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:21,234] Trial 4 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:22,326] Trial 5 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:23,271] Trial 6 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:24,192] Trial 7 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:25,184] Trial 8 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:26,195] Trial 9 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:27,449] Trial 10 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:28,299] Trial 11 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:29,199] Trial 12 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:30,168] Trial 13 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:30,993] Trial 14 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:31,955] Trial 15 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:32,824] Trial 16 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:33,693] Trial 17 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:34,883] Trial 18 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:35,785] Trial 19 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:36,768] Trial 20 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:37,606] Trial 21 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:38,406] Trial 22 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:39,229] Trial 23 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:40,021] Trial 24 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:40,813] Trial 25 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:41,917] Trial 26 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:42,914] Trial 27 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:43,855] Trial 28 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:45,016] Trial 29 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:45,934] Trial 30 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:47,092] Trial 31 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:48,417] Trial 32 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:49,543] Trial 33 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:50,662] Trial 34 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:52,114] Trial 35 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:53,275] Trial 36 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:54,164] Trial 37 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:55,256] Trial 38 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:56,043] Trial 39 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:56,844] Trial 40 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:57,895] Trial 41 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:48:59,023] Trial 42 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:00,220] Trial 43 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:01,364] Trial 44 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:02,208] Trial 45 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:03,339] Trial 46 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:04,284] Trial 47 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:05,367] Trial 48 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n",
      "[I 2025-02-28 15:49:06,258] Trial 49 finished with value: 0.37827885254750254 and parameters: {'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.37827885254750254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Params: ({'grow_policy': 'depthwise'}, 0.37827885254750254)\n"
     ]
    }
   ],
   "source": [
    "# Tune XGBoost\n",
    "tuner = HyperparameterTuner(objective_func=objective_xgb, n_trials=50)\n",
    "best_params_xgb = tuner.tune(X_train, X_val, y_train, y_val)\n",
    "print(\"Best XGBoost Params:\", best_params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
